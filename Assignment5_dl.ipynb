{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#1\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Dense, Dropout, SimpleRNN, LSTM, GRU\n",
        "from keras.utils import np_utils, to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import string, random\n",
        "\n",
        "data = pd.read_csv(\"/content/name_gender.csv\")\n",
        "data['name'] = data['name'].apply(lambda x: ''.join(filter(lambda y: y in string.printable, x)))\n",
        "chars = sorted(list(set(''.join(data['name'].values))))\n",
        "\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "def train_model(cell_type, data_size):\n",
        "    data_sample = data.sample(frac=data_size, random_state=42)\n",
        "    max_len = max([len(name) for name in data_sample['name']])\n",
        "    data_X = np.zeros((len(data_sample), max_len, len(chars)), dtype=np.bool)\n",
        "    data_Y = np.zeros((len(data_sample), 2), dtype=np.bool)\n",
        "    for i, name in enumerate(data_sample['name']):\n",
        "        for j, char in enumerate(name):\n",
        "            data_X[i, j, char_to_int[char]] = 1\n",
        "        if data_sample.iloc[i]['gender'] == 'M':\n",
        "            data_Y[i, 0] = 1\n",
        "        else:\n",
        "            data_Y[i, 1] = 1\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data_X, data_Y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model = Sequential()\n",
        "    if cell_type == 'SimpleRNN':\n",
        "        model.add(SimpleRNN(128, input_shape=(max_len, len(chars))))\n",
        "    elif cell_type == 'LSTM':\n",
        "        model.add(LSTM(128, input_shape=(max_len, len(chars))))\n",
        "    elif cell_type == 'GRU':\n",
        "        model.add(GRU(128, input_shape=(max_len, len(chars))))\n",
        "    else:\n",
        "        print(\"Not an expected type\")\n",
        "        return\n",
        "\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.fit(X_train, y_train, epochs=20, batch_size=128, validation_data=(X_test, y_test), verbose=0)\n",
        "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    print(\"Cell type:\", cell_type)\n",
        "    print(\"Data size:\", data_size)\n",
        "    print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_test_classes = np.argmax(y_test, axis=1)\n",
        "    male_indices = np.where(y_test_classes == 0)[0]\n",
        "    female_indices = np.where(y_test_classes == 1)[0]\n",
        "    male_acc = np.mean(y_pred_classes[male_indices] == y_test_classes[male_indices])\n",
        "    female_acc = np.mean(y_pred_classes[female_indices] == y_test_classes[female_indices])\n",
        "    print(\"Male accuracy: %.2f%%\" % (male_acc*100))\n",
        "    print(\"Female accuracy: %.2f%%\" % (female_acc*100))\n",
        "    print()\n",
        "\n",
        "for cell_type in ['SimpleRNN', 'LSTM', 'GRU']:\n",
        "        for data_size in [0.25, 0.5, 0.75, 1.0]:\n",
        "            train_model(cell_type, data_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mY0YxdG61VcP",
        "outputId": "beb0a5f6-6fa3-4279-f4d7-711a4f086962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-d3c58a657e67>:19: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  data_X = np.zeros((len(data_sample), max_len, len(chars)), dtype=np.bool)\n",
            "<ipython-input-5-d3c58a657e67>:20: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  data_Y = np.zeros((len(data_sample), 2), dtype=np.bool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cell type: SimpleRNN\n",
            "Data size: 0.25\n",
            "Accuracy: 84.74%\n",
            "149/149 [==============================] - 1s 3ms/step\n",
            "Male accuracy: 77.56%\n",
            "Female accuracy: 88.79%\n",
            "\n",
            "Cell type: SimpleRNN\n",
            "Data size: 0.5\n",
            "Accuracy: 87.53%\n",
            "297/297 [==============================] - 1s 3ms/step\n",
            "Male accuracy: 83.47%\n",
            "Female accuracy: 89.92%\n",
            "\n",
            "Cell type: SimpleRNN\n",
            "Data size: 0.75\n",
            "Accuracy: 87.17%\n",
            "446/446 [==============================] - 1s 3ms/step\n",
            "Male accuracy: 82.99%\n",
            "Female accuracy: 89.57%\n",
            "\n",
            "Cell type: SimpleRNN\n",
            "Data size: 1.0\n",
            "Accuracy: 88.45%\n",
            "594/594 [==============================] - 2s 3ms/step\n",
            "Male accuracy: 85.39%\n",
            "Female accuracy: 90.24%\n",
            "\n",
            "Cell type: LSTM\n",
            "Data size: 0.25\n",
            "Accuracy: 86.03%\n",
            "149/149 [==============================] - 1s 2ms/step\n",
            "Male accuracy: 78.26%\n",
            "Female accuracy: 90.40%\n",
            "\n",
            "Cell type: LSTM\n",
            "Data size: 0.5\n",
            "Accuracy: 88.56%\n",
            "297/297 [==============================] - 1s 2ms/step\n",
            "Male accuracy: 83.67%\n",
            "Female accuracy: 91.44%\n",
            "\n",
            "Cell type: LSTM\n",
            "Data size: 0.75\n",
            "Accuracy: 89.27%\n",
            "446/446 [==============================] - 1s 2ms/step\n",
            "Male accuracy: 89.03%\n",
            "Female accuracy: 89.40%\n",
            "\n",
            "Cell type: LSTM\n",
            "Data size: 1.0\n",
            "Accuracy: 90.07%\n",
            "594/594 [==============================] - 2s 3ms/step\n",
            "Male accuracy: 87.05%\n",
            "Female accuracy: 91.84%\n",
            "\n",
            "Cell type: GRU\n",
            "Data size: 0.25\n",
            "Accuracy: 85.61%\n",
            "149/149 [==============================] - 1s 2ms/step\n",
            "Male accuracy: 86.85%\n",
            "Female accuracy: 84.91%\n",
            "\n",
            "Cell type: GRU\n",
            "Data size: 0.5\n",
            "Accuracy: 88.87%\n",
            "297/297 [==============================] - 1s 2ms/step\n",
            "Male accuracy: 88.87%\n",
            "Female accuracy: 88.87%\n",
            "\n",
            "Cell type: GRU\n",
            "Data size: 0.75\n",
            "Accuracy: 89.77%\n",
            "446/446 [==============================] - 1s 2ms/step\n",
            "Male accuracy: 87.24%\n",
            "Female accuracy: 91.22%\n",
            "\n",
            "Cell type: GRU\n",
            "Data size: 1.0\n",
            "Accuracy: 90.79%\n",
            "594/594 [==============================] - 2s 2ms/step\n",
            "Male accuracy: 88.24%\n",
            "Female accuracy: 92.28%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2\n",
        "import pandas as pd\n",
        "import random, csv\n",
        "\n",
        "# load the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv('/content/name_gender.csv')\n",
        "\n",
        "# filter out the rows where gender is unknown or probability is less than 1\n",
        "df = df[(df['gender'] != 'U') & (df['probability'] == 1)]\n",
        "\n",
        "# create a dictionary to store the frequency of each character transition\n",
        "def create_transition_dict(names):\n",
        "    transition_dict = {}\n",
        "    for name in names:\n",
        "        name = name.lower()\n",
        "        for i in range(len(name)-1):\n",
        "            current_char = name[i]\n",
        "            next_char = name[i+1]\n",
        "            if current_char not in transition_dict:\n",
        "                transition_dict[current_char] = {}\n",
        "            if next_char not in transition_dict[current_char]:\n",
        "                transition_dict[current_char][next_char] = 0\n",
        "            transition_dict[current_char][next_char] += 1\n",
        "    return transition_dict\n",
        "\n",
        "# generate a name based on the Markov Chain model\n",
        "def generate_name(transition_dict, gender):\n",
        "    vowels = 'aeiou'\n",
        "    consonants = 'bcdfghjklmnpqrstvwxyz'\n",
        "    if gender == 'M':\n",
        "        first_letter = random.choice(['a', 'e', 'i', 'o', 'u'] + list(consonants))\n",
        "    else:\n",
        "        first_letter = random.choice(['a', 'e', 'i', 'o', 'u'] + list(vowels))\n",
        "    name = first_letter\n",
        "    current_letter = first_letter\n",
        "    while len(name) < 10:\n",
        "        if current_letter not in transition_dict:\n",
        "            break\n",
        "        next_letter = random.choices(list(transition_dict[current_letter].keys()), \n",
        "                                      list(transition_dict[current_letter].values()))[0]\n",
        "        name += next_letter\n",
        "        current_letter = next_letter\n",
        "    return name.capitalize()\n",
        "\n",
        "# create a list of male and female names using the Markov Chain model\n",
        "male_names = []\n",
        "female_names = []\n",
        "transition_dict = create_transition_dict(df['name'].values)\n",
        "for index, row in df.iterrows():\n",
        "    if row['gender'] == 'M':\n",
        "        male_names.append(generate_name(transition_dict, 'M'))\n",
        "    else:\n",
        "        female_names.append(generate_name(transition_dict, 'F'))\n",
        "\n",
        "with open('/content/generated_names.csv', mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Write the header row\n",
        "    writer.writerow(['gender', 'name'])\n",
        "\n",
        "    # Write the male names\n",
        "    for name in male_names:\n",
        "        writer.writerow(['M', name])\n",
        "\n",
        "    # Write the female names\n",
        "    for name in female_names:\n",
        "        writer.writerow(['F', name])\n",
        "\n",
        "# print the generated names\n",
        "print(\"Generated Male Names:\")\n",
        "for name in male_names[:100]:\n",
        "    print(name)\n",
        "print(\"\\nGenerated Female Names:\")\n",
        "for name in female_names[:100]:\n",
        "    print(name)\n",
        "\n",
        "data = pd.read_csv(\"/content/generated_names.csv\")\n",
        "data['name'] = data['name'].apply(lambda x: ''.join(filter(lambda y: y in string.printable, x)))\n",
        "chars = sorted(list(set(''.join(data['name'].values))))\n",
        "\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "male_count = 0\n",
        "for name in male_names:\n",
        "    if train_model(\"GRU\", 1.0) == \"M\":\n",
        "        male_count += 1\n",
        "        male_accuracy = male_count / len(male_names)\n",
        "        exit\n",
        "\n",
        "female_count = 0\n",
        "for name in female_names:\n",
        "    if train_model(\"GRU\", 1.0) == \"F\":\n",
        "        female_count += 1\n",
        "        female_accuracy = female_count / len(female_names)\n",
        "        exit\n",
        "\n",
        "print(\"Accuracy on generated male names: \", male_accuracy)\n",
        "print(\"Accuracy on generated female names: \", female_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2dgHV-BWIZ47",
        "outputId": "38dd03f8-1d47-4740-f131-ea40bb456e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Male Names:\n",
            "Nedeqeteri\n",
            "Ponnaioddi\n",
            "Cansiruman\n",
            "Lyleiaphir\n",
            "Trkovanior\n",
            "Vonekannia\n",
            "Brelyrmmai\n",
            "Onneogrene\n",
            "Qunienizey\n",
            "Chavaleial\n",
            "Vabrdeltre\n",
            "Vihahanday\n",
            "Eresobelon\n",
            "Eanneahand\n",
            "Nlarsidrah\n",
            "Linararomo\n",
            "Phebrecoha\n",
            "Ligistinna\n",
            "Carifayula\n",
            "Anclilerau\n",
            "Shatohahir\n",
            "Llleanadit\n",
            "Ntcharmari\n",
            "Haiamiavid\n",
            "Eraronoseu\n",
            "Frnadoakej\n",
            "Hargianava\n",
            "Mionaniken\n",
            "Zmandaberi\n",
            "Ontatobhay\n",
            "Uaneliando\n",
            "Qunnninnnt\n",
            "Beitrriond\n",
            "Pazeadicai\n",
            "Lejameraia\n",
            "Waschabimi\n",
            "Quarinewar\n",
            "Eerruithau\n",
            "Thayahnzow\n",
            "Alkeilinyc\n",
            "Ozelavolan\n",
            "Quizalelol\n",
            "Crishanttt\n",
            "Sanjulosta\n",
            "Shanilllbi\n",
            "Qubrelllia\n",
            "Jeyaynahia\n",
            "Arandameel\n",
            "Thiarayner\n",
            "Ourasstham\n",
            "Larerugrah\n",
            "Isheayorrt\n",
            "Kaynerliky\n",
            "Wolladhaha\n",
            "Zenwacager\n",
            "Hrinosonnk\n",
            "Fikishaylo\n",
            "Jeryrianyu\n",
            "Wemeartauh\n",
            "Wnarianaic\n",
            "Maraianabe\n",
            "Vorithneys\n",
            "Zallandaro\n",
            "Alfrienell\n",
            "Gralanenil\n",
            "Wantayveso\n",
            "Atonzelyne\n",
            "Ghagelinio\n",
            "Preyeianen\n",
            "Larubeland\n",
            "Zelarranna\n",
            "Xllenyntya\n",
            "Jadolynnak\n",
            "Cawynnylip\n",
            "Geylezaiyl\n",
            "Ionnedaynn\n",
            "Shynnnnitr\n",
            "Ypondecopa\n",
            "Pplamsarin\n",
            "Wyariamame\n",
            "Liberianti\n",
            "Canerionse\n",
            "Fesanialle\n",
            "Unatrichol\n",
            "Esharieeli\n",
            "Matrirshya\n",
            "Iemarilifa\n",
            "Yammarettr\n",
            "Vondeariha\n",
            "Ureliaunyr\n",
            "Qucheoname\n",
            "Ffrengrrul\n",
            "Qudalahesa\n",
            "Onedaharon\n",
            "Zeaesagitr\n",
            "Elarubinet\n",
            "Chtenderau\n",
            "Yushidatod\n",
            "Zasthracay\n",
            "Yahallelia\n",
            "\n",
            "Generated Female Names:\n",
            "Eshohahaui\n",
            "Ahikaleson\n",
            "Eranetissh\n",
            "Oleahahkni\n",
            "Ushaumhati\n",
            "Eoyalanerd\n",
            "Orenelaror\n",
            "Iquniendia\n",
            "Ilynardedo\n",
            "Ardiariali\n",
            "Osiaeysagl\n",
            "Omatheleta\n",
            "Esiahnannt\n",
            "Ucheexzann\n",
            "Adrasharam\n",
            "Amolinaena\n",
            "Ayselorika\n",
            "Ujakerinic\n",
            "Elyshareel\n",
            "Osionomeiy\n",
            "Ondrajanos\n",
            "Ikayoritam\n",
            "Ullcheanek\n",
            "Itarailong\n",
            "Usannnorsi\n",
            "Ejahurayod\n",
            "Inaheeicav\n",
            "Uarnandeur\n",
            "Acestaneis\n",
            "Aidichiave\n",
            "Oziyabeana\n",
            "Ahinishecc\n",
            "Ekyeselene\n",
            "Inajohahka\n",
            "Ushiyarela\n",
            "Onasequrbe\n",
            "Istarcabue\n",
            "Anarajarer\n",
            "Esheckigar\n",
            "Erioramala\n",
            "Uayndyaanz\n",
            "Oriaindaiz\n",
            "Ueletlohah\n",
            "Aymaneleck\n",
            "Ianhomadsh\n",
            "Ialyoshiej\n",
            "Uetohusesh\n",
            "Ishamomant\n",
            "Orikariaic\n",
            "Onaronthos\n",
            "Uineirorel\n",
            "Onarshashi\n",
            "Elymahiriy\n",
            "Aropiatise\n",
            "Errtishami\n",
            "Uemalannni\n",
            "Ierulionin\n",
            "Eiemunelia\n",
            "Onandaelat\n",
            "Uclelylase\n",
            "Omashenttr\n",
            "Urarlyrush\n",
            "Errayclika\n",
            "Uslynadret\n",
            "Eladaririy\n",
            "Usonushaas\n",
            "Icerizeris\n",
            "Ushanadtal\n",
            "Ielelvernd\n",
            "Omaianauli\n",
            "Onnnnelara\n",
            "Uielohaber\n",
            "Eaeeianeor\n",
            "Iqurnahaya\n",
            "Uvadyntisu\n",
            "Oniamuannd\n",
            "Ayradanere\n",
            "Amennelena\n",
            "Orimimayvi\n",
            "Armeavinau\n",
            "Amonkiadon\n",
            "Oriillerah\n",
            "Udesitrans\n",
            "Iyyliequah\n",
            "Uahaezaurg\n",
            "Urclyielol\n",
            "Itedoneram\n",
            "Uruayngeze\n",
            "Eliqulyuhi\n",
            "Alerakelus\n",
            "Onndosinni\n",
            "Oveloniele\n",
            "Ororinerym\n",
            "Elereteles\n",
            "Orieeeause\n",
            "Erozenimue\n",
            "Arlalykala\n",
            "Amudajilyr\n",
            "Enahiryaev\n",
            "Eshabeizon\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-d3c58a657e67>:19: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  data_X = np.zeros((len(data_sample), max_len, len(chars)), dtype=np.bool)\n",
            "<ipython-input-5-d3c58a657e67>:20: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  data_Y = np.zeros((len(data_sample), 2), dtype=np.bool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cell type: GRU\n",
            "Data size: 1.0\n",
            "Accuracy: 93.31%\n",
            "530/530 [==============================] - 1s 2ms/step\n",
            "Male accuracy: 80.51%\n",
            "Female accuracy: 100.00%\n",
            "\n",
            "Cell type: GRU\n",
            "Data size: 1.0\n",
            "Accuracy: 93.30%\n",
            "530/530 [==============================] - 2s 3ms/step\n",
            "Male accuracy: 80.50%\n",
            "Female accuracy: 100.00%\n",
            "\n",
            "Cell type: GRU\n",
            "Data size: 1.0\n",
            "Accuracy: 93.31%\n",
            "530/530 [==============================] - 1s 2ms/step\n",
            "Male accuracy: 80.51%\n",
            "Female accuracy: 100.00%\n",
            "\n",
            "Cell type: GRU\n",
            "Data size: 1.0\n",
            "Accuracy: 93.31%\n",
            "530/530 [==============================] - 2s 2ms/step\n",
            "Male accuracy: 80.51%\n",
            "Female accuracy: 100.00%\n",
            "\n",
            "Cell type: GRU\n",
            "Data size: 1.0\n",
            "Accuracy: 93.31%\n",
            "530/530 [==============================] - 1s 2ms/step\n",
            "Male accuracy: 80.51%\n",
            "Female accuracy: 100.00%\n",
            "\n",
            "Cell type: GRU\n",
            "Data size: 1.0\n",
            "Accuracy: 93.31%\n",
            "530/530 [==============================] - 2s 3ms/step\n",
            "Male accuracy: 80.51%\n",
            "Female accuracy: 100.00%\n",
            "\n",
            "Cell type: GRU\n",
            "Data size: 1.0\n",
            "Accuracy: 93.31%\n",
            "530/530 [==============================] - 2s 3ms/step\n",
            "Male accuracy: 80.51%\n",
            "Female accuracy: 100.00%\n",
            "\n",
            "Cell type: GRU\n",
            "Data size: 1.0\n",
            "Accuracy: 93.31%\n",
            "530/530 [==============================] - 1s 2ms/step\n",
            "Male accuracy: 80.51%\n",
            "Female accuracy: 100.00%\n",
            "\n",
            "Cell type: GRU\n",
            "Data size: 1.0\n",
            "Accuracy: 93.31%\n",
            "530/530 [==============================] - 1s 2ms/step\n",
            "Male accuracy: 80.51%\n",
            "Female accuracy: 100.00%\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-74d34989a174>\u001b[0m in \u001b[0;36m<cell line: 84>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0mmale_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmale_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GRU\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"M\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mmale_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mmale_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmale_count\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmale_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-d3c58a657e67>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(cell_type, data_size)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2a\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "from keras.utils import np_utils\n",
        "import nltk\n",
        "\n",
        "nltk.download('names')\n",
        "\n",
        "names = nltk.corpus.names.words('/content/name_gender.csv')\n",
        "names = [name.lower() for name in names if name[0].lower() in ['a', 'm', 'z']]\n",
        "\n",
        "chars = sorted(list(set(' '.join(names))))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "seq_length = 10\n",
        "dataX = []\n",
        "dataY = []\n",
        "for name in names:\n",
        "    for i in range(len(name)-seq_length):\n",
        "        seq_in = name[i:i+seq_length]\n",
        "        seq_out = name[i+seq_length]\n",
        "        dataX.append([char_to_int[char] for char in seq_in])\n",
        "        dataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "\n",
        "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "X = X / float(len(chars))\n",
        "y = np_utils.to_categorical(dataY)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "model.fit(X, y, epochs=20, batch_size=128)\n",
        "\n",
        "for i in range(50):\n",
        "    start = np.random.randint(0, len(dataX)-1)\n",
        "    pattern = dataX[start]\n",
        "    name = [int_to_char[value] for value in pattern]\n",
        "\n",
        "    for j in range(20):\n",
        "        x = np.reshape(pattern, (1, len(pattern), 1))\n",
        "        x = x / float(len(chars))\n",
        "        prediction = model.predict(x, verbose=0)\n",
        "        index = np.argmax(prediction)\n",
        "        result = int_to_char[index]\n",
        "        name.append(result)\n",
        "        pattern.append(index)\n",
        "        pattern = pattern[1:len(pattern)]\n",
        "        if result == '.':\n",
        "            break\n",
        "\n",
        "    print(''.join(name).capitalize())\n",
        "\n",
        "split_index = int(len(dataX)*0.9)\n",
        "trainX, testX = dataX[:split_index], dataX[split_index:]\n",
        "trainY, testY = dataY[:split_index], dataY[split_index:]\n",
        "\n",
        "testX = np.reshape(testX, (len(testX), seq_length, 1))\n",
        "testX = testX / float(len(chars))\n",
        "testY = np_utils.to_categorical(testY)    \n",
        "\n",
        "perplexities = []\n",
        "for i in range(50):\n",
        "    start = np.random.randint(0, len(testX)-1)\n",
        "    pattern = testX[start]\n",
        "    name = [int_to_char[value] for value in pattern.flatten()]\n",
        "\n",
        "    perplexity = 1.0\n",
        "    for j in range(20):\n",
        "        x = np.reshape(pattern, (1, len(pattern), 1))\n",
        "        x = x / float(len(chars))\n",
        "        prediction = model.predict(x, verbose=0)\n",
        "        index = np.argmax(prediction)\n",
        "        result = int_to_char[index]\n",
        "        name.append(result)\n",
        "        pattern = np.append(pattern, index)\n",
        "        pattern = pattern[1:len(pattern)]\n",
        "        if result == '.':\n",
        "            break\n",
        "        perplexity *= prediction[0][index]\n",
        "    \n",
        "    perplexity = pow(perplexity, -1/len(name))\n",
        "    perplexities.append(perplexity)\n",
        "    print(''.join(name).capitalize(), 'Perplexity:', perplexity)\n",
        "\n",
        "avg_perplexity = sum(perplexities) / len(perplexities)\n",
        "print('Average Perplexity:', avg_perplexity)    "
      ],
      "metadata": {
        "id": "oCLrKLcFdJMJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de8f5321-cc99-4ba1-f478-f526b64f58c0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Package names is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "355/355 [==============================] - 3s 4ms/step - loss: 2.1043\n",
            "Epoch 2/20\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 1.6254\n",
            "Epoch 3/20\n",
            "355/355 [==============================] - 2s 5ms/step - loss: 1.5187\n",
            "Epoch 4/20\n",
            "355/355 [==============================] - 2s 5ms/step - loss: 1.4971\n",
            "Epoch 5/20\n",
            "355/355 [==============================] - 2s 4ms/step - loss: 1.4859\n",
            "Epoch 6/20\n",
            "355/355 [==============================] - 2s 4ms/step - loss: 1.4774\n",
            "Epoch 7/20\n",
            "355/355 [==============================] - 2s 4ms/step - loss: 1.4725\n",
            "Epoch 8/20\n",
            "355/355 [==============================] - 2s 4ms/step - loss: 1.4677\n",
            "Epoch 9/20\n",
            "355/355 [==============================] - 2s 4ms/step - loss: 1.4667\n",
            "Epoch 10/20\n",
            "355/355 [==============================] - 2s 4ms/step - loss: 1.4634\n",
            "Epoch 11/20\n",
            "355/355 [==============================] - 2s 5ms/step - loss: 1.4610\n",
            "Epoch 12/20\n",
            "355/355 [==============================] - 2s 5ms/step - loss: 1.4592\n",
            "Epoch 13/20\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 1.4582\n",
            "Epoch 14/20\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 1.4563\n",
            "Epoch 15/20\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 1.4539\n",
            "Epoch 16/20\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 1.4532\n",
            "Epoch 17/20\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 1.4518\n",
            "Epoch 18/20\n",
            "355/355 [==============================] - 1s 4ms/step - loss: 1.4497\n",
            "Epoch 19/20\n",
            "355/355 [==============================] - 2s 5ms/step - loss: 1.4468\n",
            "Epoch 20/20\n",
            "355/355 [==============================] - 2s 5ms/step - loss: 1.4451\n",
            "Ilarose,f,1.\n",
            "Morissa,f,1.\n",
            "333333333372727272727272727272\n",
            "En,f,0.99766676766666666666666\n",
            "523985239876666666666666666666\n",
            "666666666666666666666666666666\n",
            "507002801172727276627276627676\n",
            "915492957762766662766662766662\n",
            "Moniesha,f,1.\n",
            "Erlin,m,0.99766666766666666666\n",
            "Nastashia,f,1.\n",
            ".98314606727727627627627627627\n",
            "Ery,m,0.9976666676666666666666\n",
            "Ddilynn,f,1.\n",
            "032177444577666666666666666666\n",
            "Oey,f,0.9976667676666666666666\n",
            "Murlyn,m,0.\n",
            "Artiana,f,1.\n",
            "0.9991299271777276767276666276\n",
            "0.8539923969717667727666627666\n",
            "M,0.97099766266666276666276666\n",
            "333333333372727272727272727272\n",
            "Marleen,f,1.\n",
            "Ustinjohn,m,1.\n",
            "Zariyah,f,1.\n",
            "Andra,f,0.99766676766666666666\n",
            "Arrow,m,0.99766666766666666666\n",
            "0.9982598172767276766276666276\n",
            "L,f,0.854076777276666276666276\n",
            "Nterrius,m,1.\n",
            "Atiyanna,f,1.\n",
            "042253521176727276727666627666\n",
            "117647058827176727176627276627\n",
            "Rewjacob,m,1.\n",
            "M,0.75987866688666678666666666\n",
            ",0.996995766876666666666666666\n",
            ",0.986146077277276276276276276\n",
            "459129001227667766666666666666\n",
            "Onterio,m,1.\n",
            "546229563327672727672766662766\n",
            ",m,0.6048376666666666666666666\n",
            "Ariyonna,f,1.\n",
            ",0.793209877667666666666666666\n",
            "Ckendra,f,1.\n",
            "Rin,f,0.6876666666666666666666\n",
            "Rgarete,f,1.\n",
            "423728813567717666727666627666\n",
            "Musiq,m,0.99766666766666666666\n",
            "666666666666666666666666666666\n",
            "Ichaelryan,f,1.\n"
          ]
        }
      ]
    }
  ]
}